{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imslp import client, interfaces, helpers\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "import requests\n",
    "import typing\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches_meta_attribute(header_text):\n",
    "    for attribute in META_ATTRIBUTES:\n",
    "        if attribute in header_text or header_text in attribute:\n",
    "            return attribute\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if header text matches any target attribute, accounting for nested span tags\n",
    "def header_matches_meta_attribute(header):\n",
    "    # Normalize header text by stripping and joining with space if span-separated\n",
    "    header_text = ' '.join(header.stripped_strings)\n",
    "    for attribute in META_ATTRIBUTES:\n",
    "        if attribute in header_text or header_text in attribute:\n",
    "            return attribute\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_general_info(div: Tag):\n",
    "    metadata = {}\n",
    "    \n",
    "    for row in div.find_all(\"tr\"):\n",
    "        header_cell = row.find(\"th\")\n",
    "        value_cell = row.find(\"td\")\n",
    "        \n",
    "        if header_cell and value_cell:\n",
    "            matched_attribute = header_matches_meta_attribute(header_cell)\n",
    "            \n",
    "            # If there's a matching attribute, process the value\n",
    "            if matched_attribute:\n",
    "                if matched_attribute == \"External Links\":\n",
    "                    links = [a['href'] for a in value_cell.find_all(\"a\", href=True)]\n",
    "                    metadata[matched_attribute] = links\n",
    "                elif matched_attribute in \"Movements/Sections\":\n",
    "                    # print(\"DATA\")\n",
    "                    # print(value_cell)\n",
    "                    metadata[matched_attribute] = handle_movements(value_cell)\n",
    "                elif matched_attribute== 'Year/Date of Composition':\n",
    "                    year = int(value_cell.get_text()[:4])\n",
    "                    metadata[matched_attribute] = year\n",
    "                elif matched_attribute == 'Key':\n",
    "                    cleansed_key = None\n",
    "                    # enum map...\n",
    "                    if len(value_cell.get_text(\" \")) < 10: \n",
    "                        cleansed_key = value_cell.get_text(\" \", strip=True)\n",
    "                    metadata[matched_attribute] = cleansed_key\n",
    "                else:\n",
    "                    # General case for other fields, removing non-breaking spaces\n",
    "                    clean_text = value_cell.get_text(\" \", strip=True).replace('\\xa0', ' ')\n",
    "                    metadata[matched_attribute] = clean_text\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_movements(data: Tag):\n",
    "    movements = []\n",
    "\n",
    "    # Helper function to extract a leading number if present\n",
    "    def extract_number(name, default_index):\n",
    "        match = re.match(r\"(\\d+)\\.\", name)  # Look for a leading digit followed by a dot\n",
    "        return int(match.group(1)) if match else default_index + 1\n",
    "\n",
    "    # Check for ordered list (<ol>) for movements\n",
    "    movement_list = data.find('ol')\n",
    "    if movement_list:\n",
    "        for index, li in enumerate(movement_list.find_all('li')):\n",
    "            line = li.get_text(strip=True).replace(\"\\xa0\", \" \")\n",
    "            number = extract_number(line, index)  # Extract number or use index\n",
    "            \n",
    "            if \"(\" in line and line.endswith(\")\"):\n",
    "                name, key_signature = line.rsplit(\"(\", 1)\n",
    "                key_signature = key_signature.rstrip(\")\").replace(\"\\xa0\", \" \")\n",
    "                movements.append({\n",
    "                    \"type\": \"movement\",\n",
    "                    \"number\": number,\n",
    "                    \"name\": name.strip(),\n",
    "                    \"key_signature\": key_signature.strip()\n",
    "                })\n",
    "            else:\n",
    "                movements.append({\n",
    "                    \"type\": \"movement\",\n",
    "                    \"number\": number,\n",
    "                    \"name\": line.strip(),\n",
    "                    \"key_signature\": None\n",
    "                })\n",
    "\n",
    "    # Check for description list (<dl>) for suite pieces\n",
    "    piece_list = data.find('dl')\n",
    "    if piece_list:\n",
    "        for index, dd in enumerate(piece_list.find_all('dd')):\n",
    "            line = dd.get_text(strip=True).replace(\"\\xa0\", \" \")\n",
    "            number = extract_number(line, index)  # Extract number or use index\n",
    "            \n",
    "            if \"(\" in line and line.endswith(\")\"):\n",
    "                name, key_signature = line.rsplit(\"(\", 1)\n",
    "                key_signature = key_signature.rstrip(\")\").replace(\"\\xa0\", \" \")\n",
    "                movements.append({\n",
    "                    \"type\": \"piece\",\n",
    "                    \"number\": number,\n",
    "                    \"name\": name.strip(),\n",
    "                    \"key_signature\": key_signature.strip()\n",
    "                })\n",
    "            else:\n",
    "                movements.append({\n",
    "                    \"type\": \"piece\",\n",
    "                    \"number\": number,\n",
    "                    \"name\": line.strip(),\n",
    "                    \"key_signature\": None\n",
    "                })\n",
    "\n",
    "    return movements\n",
    "# handle_movements(general_info_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'imslp.client' has no attribute 'search_works'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_works\u001b[49m(composer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRachmaninoff\u001b[39m\u001b[38;5;124m\"\u001b[39m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreludes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'imslp.client' has no attribute 'search_works'"
     ]
    }
   ],
   "source": [
    "results = client.search_works(composer=\"Rachmaninoff\", title=\"Preludes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "META_ATTRIBUTES = ['Work Title', 'Opus/Catalogue Number', 'Key', 'Year/Date of Composition', 'Piece Style', 'External Links', 'Movements/Section' ]\n",
    "for index, result in enumerate(results):\n",
    "    url = result['permlink']\n",
    "    data = requests.get(url)\n",
    "    soup = BeautifulSoup(data.content, \"html.parser\")\n",
    "    # print(soup.prettify())\n",
    "    # for file_block in soup.select('.we_file_first, .we_file_hideentry'):\n",
    "    # # Get the title and download link\n",
    "    #     title_tag = file_block.select_one('.we_file_download a.external.text')\n",
    "    #     print(title_tag)\n",
    "    #     title = title_tag.text.strip() if title_tag else \"N/A\"\n",
    "    #     download_link = title_tag['href'] if title_tag else \"N/A\"\n",
    "    #     print(download_link)\n",
    "        \n",
    "        # Get file information (size and pages)\n",
    "\n",
    "            \n",
    "    # print(f\"Title: {title}\")\n",
    "    # print(f\"Download Link: {download_link}\")\n",
    "\n",
    "    # print(\"-\" * 40)\n",
    "    # Find the div that contains the metadata table\n",
    "    # general_info_div = soup.find(\"div\", class_=\"wi_body\")\n",
    "    \n",
    "    # # # print(general_info_div)\n",
    "    # print(process_general_info(general_info_div))\n",
    "    # break\n",
    "    break\n",
    "    # break  # Remove this if you want to process more than just the second item\n",
    "    # il mio primo chopin?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
